# Autonomous Data Labeling for Domain-Specific LLM Fine-Tuning

**A research framework that dramatically reduces the cost and time of labeling training data for domain-specific LLM fine-tuning through reasoning pattern analysis.**

## Abstract

We address the scalability challenge in data labeling for domain-specific LLM fine-tuning through reasoning pattern analysis. Our framework enables **autonomous data labeling at scale** by analyzing reasoning patterns in chain-of-thought (CoT) explanations rather than surface text features.

The core innovation is that reasoning quality can be assessed and propagated independent of surface semantics - allowing a single human evaluation to inform labeling decisions across hundreds of similar reasoning structures. Instead of manually labeling each example, we label a few representative reasoning patterns, and our system automatically propagates those labels based on **logical structure rather than surface semantics**.

Our approach achieves 83.3% accuracy on held-out test data while demonstrating cross-domain generalization capabilities.

## ğŸ¯ **Research Objective**

**Primary Goal**: Demonstrate that reasoning patterns can enable autonomous data labeling, allowing label propagation based on **logical structure rather than surface semantics**.

**The Problem**: Manual labeling of training data for domain-specific LLM fine-tuning is time-intensive and doesn't scale efficiently.

**Our Approach**: Instead of labeling individual examples, we label **reasoning patterns** and automatically propagate those labels to structurally similar examples.

### **Core Innovation**
A dual CoT comparison methodology that forces genuine reasoning quality assessment, preventing surface artifact exploitation while enabling scalable label propagation across diverse domains.

**Key Contributions**:
- **Reasoning-First Labeling**: Shift from individual examples to reasoning structure analysis
- **Artifact-Resistant Methodology**: Dual comparison prevents surface pattern exploitation  
- **Cross-Domain Generalization**: Logical structures transfer between unrelated domains
- **Production-Ready Pipeline**: Autonomous labeling system achieving 83.3% accuracy

## ğŸ“ˆ **Current Results & Performance**

### **Production-Grade Performance Metrics**
```
Validated Performance:
ğŸ¯ 83.3% accuracy on rigorous held-out test set
ğŸ¯ 70.0% accuracy on completely new cross-domain data
ğŸ¯ Artifact-resistant methodology verified (prevents surface pattern exploitation)
ğŸ¯ Cross-domain generalization demonstrated across multiple reasoning types
```

## ğŸ—ï¸ **System Architecture**

```
cot-clustering-test/
â”œâ”€â”€ ğŸŒ **FRONTEND** (Next.js 13+ App Router)
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ app/
â”‚           â”œâ”€â”€ layout.js              # Root layout
â”‚           â”œâ”€â”€ page.js                # Home page
â”‚           â”œâ”€â”€ favicon.ico            # App icon
â”‚           â”œâ”€â”€ api/                   # Next.js API routes
â”‚           â”‚   â”œâ”€â”€ export-cots/       # CoT export endpoint
â”‚           â”‚   â”œâ”€â”€ generate-cots/     # CoT generation endpoint
â”‚           â”‚   â”œâ”€â”€ hdbscan/           # Clustering endpoint
â”‚           â”‚   â”œâ”€â”€ propagate/         # Label propagation endpoint
â”‚           â”‚   â””â”€â”€ representatives/   # Representative selection
â”‚           â”œâ”€â”€ clusters/              # Clusters page
â”‚           â”œâ”€â”€ propagation/           # Propagation page
â”‚           â”œâ”€â”€ components/            # React components
â”‚           â”œâ”€â”€ styles/                # CSS styling
â”‚           â””â”€â”€ types/                 # TypeScript definitions
â”‚
â”œâ”€â”€ ğŸ”§ **BACKEND** (FastAPI)
â”‚   â””â”€â”€ backend/
â”‚       â”œâ”€â”€ main.py                    # FastAPI entry point
â”‚       â”œâ”€â”€ requirements.txt           # Python dependencies
â”‚       â”œâ”€â”€ src/                       # Backend source code
â”‚       â”‚   â”œâ”€â”€ api/                   # API routes
â”‚       â”‚   â”œâ”€â”€ models/                # Data models
â”‚       â”‚   â”œâ”€â”€ services/              # Business logic
â”‚       â”‚   â””â”€â”€ utils/                 # Utility functions
â”‚       â””â”€â”€ notebooks/                 # Research notebooks
â”‚
â”œâ”€â”€ ğŸ¤– **ML MODELS** (Production Ready)
â”‚   â””â”€â”€ ml-models/
â”‚       â”œâ”€â”€ binary_choice_classifier.py               # Main classifier (83.3% accuracy)
â”‚       â”œâ”€â”€ evaluate_binary_choice_proper.py          # Model evaluation script
â”‚       â”œâ”€â”€ run_inference_from_pinecone.py            # Full inference pipeline
â”‚       â”œâ”€â”€ best_binary_choice_model.pth              # Trained model weights
â”‚       â””â”€â”€ requirements.txt                          # ML dependencies
â”‚
â”œâ”€â”€ ğŸ“Š **DATA & UTILITIES**
â”‚   â”œâ”€â”€ data/                          # All datasets and embeddings
â”‚   â”‚   â”œâ”€â”€ all_300_cots.json          # Complete CoT dataset
â”‚   â”‚   â”œâ”€â”€ all_300_embeddings.json    # Pre-computed embeddings
â”‚   â”‚   â”œâ”€â”€ cleaned_questions_answers.csv  # Production dataset
â”‚   â”‚   â””â”€â”€ dual_embeddings_cache.npz  # Cached embeddings
â”‚   â”œâ”€â”€ scripts/                       # Utility and processing scripts
â”‚   â”‚   â”œâ”€â”€ embed-and-upload.js        # Embedding generation
â”‚   â”‚   â”œâ”€â”€ upload_embeddings.js       # Data upload utilities
â”‚   â”‚   â”œâ”€â”€ inspect_pinecone_data.py   # Database inspection
â”‚   â”‚   â””â”€â”€ sequential_upload_300.cjs  # Batch processing
â”‚   â””â”€â”€ public/                        # Static web assets
â”‚
â””â”€â”€ ğŸ“š **RESEARCH ARCHIVE**
    â”œâ”€â”€ research_archive/              # Complete research history
    â”‚   â”œâ”€â”€ phase1_clustering/         # Original clustering approach
    â”‚   â”œâ”€â”€ phase2_gnn/               # Graph neural network experiments
    â”‚   â”œâ”€â”€ phase3_aligned/           # Full aligned embedding history
    â”‚   â””â”€â”€ notebooks/                # Research analysis
    â””â”€â”€ legacy/                       # Preserved experimental files
        â”œâ”€â”€ old_inference/            # Previous inference methods
        â”œâ”€â”€ old_scripts/             # Historical utility scripts
        â””â”€â”€ temp_files/              # Experimental artifacts
```

## ğŸš€ **Quick Start**

### **1. Environment Setup**
```bash
# Copy environment template
cp env-template.txt .env.local

# Add your API keys for embedding generation:
OPENAI_API_KEY=your_openai_key
PINECONE_API_KEY=your_pinecone_key
PINECONE_INDEX_NAME=cot-clustering-test
```

### **2. Install Dependencies**
```bash
# Python dependencies for the classifier
pip install -r requirements.txt

# Or use the backend environment
cd backend
pip install -r requirements.txt
```

### **3. Test the Current System**
```bash
# Install dependencies
npm install

# Test the ML classifier
npm run test:ml

# Run inference on new data
npm run inference

# Start the web interface
npm run dev

# Or run full stack (frontend + backend)
npm run dev:full
```

### **4. Explore Research History**
```bash
# Read the complete research journey
cat RESEARCH_PROGRESS.txt

# Explore specific phases
cd research_archive/phase1_clustering/
cd research_archive/phase2_gnn/
cd research_archive/phase3_aligned/
```

## ğŸ”¬ **How It Works: Binary Choice Innovation**

### **Core Problem Solved**
Traditional approaches to reasoning quality assessment suffer from **surface artifact exploitation** - models achieve high accuracy by reading explicit evaluative language rather than assessing genuine reasoning quality.

### **Solution: Dual CoT Comparison**
```python
# Instead of: "Is this reasoning correct?" (exploitable)
# We use: "Which of these two reasoning chains is better?" (genuine assessment)

class BinaryChoiceClassifier(nn.Module):
    def __init__(self, embedding_dim=1024):
        # Separate processors for positive and negative CoTs
        self.pos_processor = nn.Sequential(
            nn.Linear(embedding_dim, 256), nn.ReLU(), 
            nn.BatchNorm1d(256), nn.Dropout(0.3)
        )
        self.neg_processor = nn.Sequential(
            nn.Linear(embedding_dim, 256), nn.ReLU(),
            nn.BatchNorm1d(256), nn.Dropout(0.3)
        )
        
        # Combined decision network (512â†’256â†’128â†’1)
        self.combined_network = nn.Sequential(
            nn.Linear(512, 256), nn.ReLU(), nn.BatchNorm1d(256), nn.Dropout(0.3),
            nn.Linear(256, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(0.3),
            nn.Linear(128, 1), nn.Sigmoid()
        )
        
        # Explicit choice mechanism (512â†’128â†’2)
        self.choice_layer = nn.Sequential(
            nn.Linear(512, 128), nn.ReLU(), nn.Linear(128, 2)
        )

def evaluate_reasoning_quality(positive_cot, negative_cot):
    # Model must actively choose between competing explanations
    # Cannot rely on pre-labeled "correct" vs "incorrect" signals
    return model.choose_better_reasoning(positive_cot, negative_cot)
```

1. **Dual CoT Input**: Model sees both positive and negative simultaneously
2. **No Pre-Selection**: Cannot read explicit quality indicators
3. **Active Choice**: Must actively decide which CoT is better
4. **Proper Evaluation**: Strict train/test split with no data leakage

### **Immediate Applications**
- **Rapid Labeling**: Tag LLM outputs across datasets using reasoning pattern analysis
- **Content Moderation**: Scalable quality detection for safety-critical deployments
- **Training Data Curation**: Identify flawed reasoning in pretraining or fine-tuning corpora
- **Evaluation**: Ground truth supervision for benchmarking reasoning ability
- **Domain-Specific Finetuning**: Reliable labeling for sensitive use cases

## ğŸ§  **Theoretical Framework: From Clustering to Semantic Backpropagation**

### **The Evolution of Ideas**

**Phase 1: Reasoning Cluster Foundation**
- **Core Hypothesis**: Similar reasoning patterns can be grouped and evaluated collectively
- **Approach**: Traditional clustering (K-means, HDBSCAN) on CoT embeddings
- **Insight**: Reasoning structure contains signal independent of surface semantics

**Phase 2: Graph Neural Networks & Trust Propagation**
- **Innovation**: Model reasoning relationships as a graph where trust signals propagate
- **Semantic Backpropagation**: Inspired by neural network backprop, human feedback becomes a "trust signal" that diffuses across similarity graphs - diminishing with distance, yet allowing structured propagation
- **Mathematical Framework**: Trust propagation via weighted similarity: `tÌ‚_j = (1/Z) Î£ exp(-Î»d_ij) Â· t_i`
- **Insight**: Error signals can be localized and corrected within neighborhoods of logic

**Phase 3: The Anti-Alignment Discovery**
- **Critical Realization**: Traditional "Is this correct?" approaches are exploitable - models learn surface artifacts rather than reasoning quality
- **Anti-Alignment Approach**: Instead of aligning to explicit correctness labels, force genuine reasoning assessment through comparative choice
- **Breakthrough**: "Which reasoning is better?" prevents artifact exploitation while preserving assessment capability

**Phase 4: Dual CoT Comparison (Current)**
- **Final Architecture**: Binary choice between competing explanations
- **Artifact Resistance**: Cannot rely on pre-labeled quality indicators
- **Validated Approach**: 83.3% accuracy with verified robustness

### **Novel Technical Contributions**

**1. Semantic Backpropagation Theory**
Drawing parallels to neural network training, we treat human feedback as error signals that propagate through a semantic similarity graph. Unlike traditional backprop which updates weights, our approach propagates trust scores across reasoning structures.

**2. Anti-Alignment Methodology** 
Deliberately avoiding explicit correctness supervision to prevent surface pattern exploitation. This counter-intuitive approach forces models to develop genuine reasoning assessment capabilities.

**3. Dual Processor Architecture**
Separate neural pathways for positive and negative reasoning chains, enabling direct comparison without pre-selection bias.

**4. Cross-Domain Reasoning Transfer**
Demonstration that logical structure generalizes across unrelated domains - a key insight for scalable supervision.

## ğŸ”§ **Development & Usage**

### **For Autonomous Data Labeling**
```bash
# ML model operations
npm run test:ml     # Train/test the classifier
npm run inference   # Label new data autonomously

# Web interface
npm run dev         # Launch the Next.js frontend
npm run dev:backend # Launch the FastAPI backend
npm run dev:full    # Launch both frontend and backend
```

### **For Research & Experimentation**
```bash
# Explore historical approaches
cd research_archive/phase1_clustering/
python experiment.py                     # Original clustering method

cd ../phase2_gnn/
# Multiple GNN-based approaches available

cd ../phase3_aligned/
# Complete history of current approach development
```

### **Technical Specifications**

**Advanced Neural Architecture:**
- **Dual Processor Design**: Twin 1024â†’256 networks with specialized positive/negative CoT processing
- **Deep Combined Decision Network**: 3-layer architecture (512â†’256â†’128â†’1) with comprehensive regularization
- **Parallel Choice Mechanism**: Independent 512â†’128â†’2 network enabling explicit comparison reasoning
- **Multi-Objective Learning**: Simultaneous optimization across binary classification + choice consistency objectives
- **Production-Grade Regularization**: Full batch normalization + strategic dropout (0.3) preventing overfitting

**Methodological Breakthroughs:**
- **Dual Loss Architecture**: Joint binary cross-entropy + choice cross-entropy optimization
- **Artifact-Resistant Training**: Prevents surface pattern exploitation through comparative methodology
- **Verified Generalization**: Rigorous train/test splits with cross-domain validation
- **Scalable Inference Pipeline**: Production-ready system processing 1024-dimensional embeddings efficiently

## ğŸ“ˆ **Future Research Directions**

### **Immediate Extensions**
- **Scale to larger datasets**
- **Multi-domain evaluation**
- **Ensemble methods**
- **Real-time inference optimization**

### **Advanced Research Questions**
- **Multi-way choice** (choose between 3+ competing explanations)
- **Confidence calibration** (quantify certainty in autonomous labeling)
- **Active learning** (identify most valuable examples to label)
- **Cross-modal reasoning** (extend beyond text to multimodal inputs)

---

## ğŸ“š **Complete Research Journey**

This system represents the culmination of extensive research through multiple methodological phases. For the complete story of failures, pivots, and breakthroughs that led to the current system, see `RESEARCH_PROGRESS.txt`.

**Research Evolution Summary:**
- **Phase 1**: Clustering Foundation â†’ 65% baseline accuracy, established reasoning pattern clustering feasibility
- **Phase 2**: Graph Neural Networks â†’ 78% accuracy, advanced methodology with sophisticated graph-based modeling
- **Phase 3**: Aligned Embeddings â†’ Invalidated due to artifact exploitation
- **Phase 4**: Binary Choice Classifier â†’ **83.3% validated accuracy** + **artifact-resistant methodology**

**Key Achievement**: Phase 4 represents the first methodology achieving both high accuracy AND verified robustness against surface pattern exploitation - the critical breakthrough for production deployment.
